{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting and splitting data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading dataset with feature engineering done! Splitting dataset into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "dataset = pd.read_csv(\"./data/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the passengerId for each cluster and test/train dataset\n",
    "id_trainW = dataset[(dataset[\"Survived\"].isnull() == False) & (dataset[\"Sex\"] == 1)][\"PassengerId\"] # Cluster 1 / train\n",
    "id_trainM = dataset[(dataset[\"Survived\"].isnull() == False) & (dataset[\"Sex\"] == 0)][\"PassengerId\"] # Cluster 2 / train\n",
    "\n",
    "id_testW = dataset[(dataset[\"Survived\"].isnull()) & (dataset[\"Sex\"] == 1)][\"PassengerId\"] # Cluster 1 / test\n",
    "id_testM = dataset[(dataset[\"Survived\"].isnull()) & (dataset[\"Sex\"] == 0)][\"PassengerId\"] # Cluster 2 / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop PassengerId in dataset\n",
    "dataset.drop(labels = [\"PassengerId\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rain / test set\n",
    "train = dataset[np.invert(dataset['Survived'].isnull())]\n",
    "test = dataset[dataset['Survived'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering dataset by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train set\n",
    "trainW = train[train['Sex']==1]\n",
    "trainM = train[train['Sex']==0]\n",
    "\n",
    "#test set\n",
    "testW = test[test['Sex']==1]\n",
    "testM = test[test['Sex']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features to use in modeling phase and target to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 1: women\n",
    "X_trainW = trainW.drop('Survived',axis=1)\n",
    "y_trainW = trainW['Survived'].astype(int)\n",
    "\n",
    "X_testW = testW.drop('Survived',axis=1)\n",
    "\n",
    "# CLuster 2: man\n",
    "X_trainM = trainM.drop('Survived',axis=1)\n",
    "y_trainM = trainM['Survived'].astype(int)\n",
    "\n",
    "X_testM = testM.drop('Survived',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensamble_modeling(X_train, y_train, X_test, folds = 10, n_jobs = 4):\n",
    "    \n",
    "    # Cross validation\n",
    "    kfold = StratifiedKFold(n_splits=folds)\n",
    "    \n",
    "    \n",
    "    # ---- MODEL 1 ---- ADABOOST ----\n",
    "    \n",
    "    DTC = DecisionTreeClassifier()\n",
    "    adaDTC = AdaBoostClassifier(DTC, random_state=7)\n",
    "\n",
    "    # Search grid for optimal parameters\n",
    "    ada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "                      \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "                      \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n",
    "                      \"n_estimators\" :[1,2],\n",
    "                      \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\n",
    "\n",
    "    gsadaDTC = GridSearchCV(adaDTC, param_grid = ada_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= n_jobs, verbose = 1)\n",
    "    \n",
    "    gsadaDTC.fit(X_train,y_train)\n",
    "    \n",
    "    ada_best = gsadaDTC.best_estimator_\n",
    "\n",
    "    # Best score\n",
    "    print(\"AdaBoost best score: {}\".format(gsadaDTC.best_score_))\n",
    "    \n",
    "    \n",
    "    # ---- MODEL 2 ---- EXTRATREES ----\n",
    "    \n",
    "    ExtC = ExtraTreesClassifier()\n",
    "\n",
    "    # Search grid for optimal parameters\n",
    "    ex_param_grid = {\"max_depth\": [None],\n",
    "                  \"max_features\": [1, 3, 10],\n",
    "                  \"min_samples_split\": [2, 3, 10],\n",
    "                  \"min_samples_leaf\": [1, 3, 10],\n",
    "                  \"bootstrap\": [False],\n",
    "                  \"n_estimators\" :[100,300],\n",
    "                  \"criterion\": [\"gini\"]}\n",
    "\n",
    "\n",
    "    gsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= n_jobs, verbose = 1)\n",
    "\n",
    "    gsExtC.fit(X_train,y_train)\n",
    "\n",
    "    ExtC_best = gsExtC.best_estimator_\n",
    "\n",
    "    # Best score\n",
    "    print(\"ExtraTrees best score: {}\".format(gsExtC.best_score_))\n",
    "    \n",
    "    \n",
    "    # ---- MODEL 3 ---- RANDOM FOREST ----\n",
    "    \n",
    "    RFC = RandomForestClassifier()\n",
    "\n",
    "    # Search grid for optimal parameters\n",
    "    rf_param_grid = {\"max_depth\": [None],\n",
    "                  \"max_features\": [1, 3, 10],\n",
    "                  \"min_samples_split\": [2, 3, 10],\n",
    "                  \"min_samples_leaf\": [1, 3, 10],\n",
    "                  \"bootstrap\": [False],\n",
    "                  \"n_estimators\" :[100,300],\n",
    "                  \"criterion\": [\"gini\"]}\n",
    "\n",
    "\n",
    "    gsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= n_jobs, verbose = 1)\n",
    "\n",
    "    gsRFC.fit(X_train,y_train)\n",
    "\n",
    "    RFC_best = gsRFC.best_estimator_\n",
    "\n",
    "    # Best score\n",
    "    print(\"RandomForest best score: {}\".format(gsRFC.best_score_))\n",
    "    \n",
    "    \n",
    "    # ---- MODEL 4 ---- Gradient Boosting ----\n",
    "\n",
    "    GBC = GradientBoostingClassifier()\n",
    "\n",
    "    # Search grid for optimal parameters\n",
    "    gb_param_grid = {'loss' : [\"deviance\"],\n",
    "                  'n_estimators' : [100,200,300],\n",
    "                  'learning_rate': [0.1, 0.05, 0.01],\n",
    "                  'max_depth': [4, 8],\n",
    "                  'min_samples_leaf': [100,150],\n",
    "                  'max_features': [0.3, 0.1] \n",
    "                  }\n",
    "\n",
    "    gsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= n_jobs, verbose = 1)\n",
    "\n",
    "    gsGBC.fit(X_train,y_train)\n",
    "\n",
    "    GBC_best = gsGBC.best_estimator_\n",
    "\n",
    "    # Best score\n",
    "    print(\"Gradient Boosting best score: {}\".format(gsGBC.best_score_))\n",
    "    \n",
    "    \n",
    "    # ---- MODEL 5 ---- SVM ----\n",
    "    SVMC = SVC(probability=True)\n",
    "\n",
    "    # Search grid for optimal parameters\n",
    "    svc_param_grid = {'kernel': ['rbf'], \n",
    "                      'gamma': [ 0.001, 0.01, 0.1, 1],\n",
    "                      'C': [1, 10, 50, 100,200,300, 1000]}\n",
    "\n",
    "    gsSVMC = GridSearchCV(SVMC,param_grid = svc_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= n_jobs, verbose = 1)\n",
    "\n",
    "    gsSVMC.fit(X_train,y_train)\n",
    "\n",
    "    SVMC_best = gsSVMC.best_estimator_\n",
    "\n",
    "    # Best score\n",
    "    print(\"Support Vector Machine best score: {}\".format(gsSVMC.best_score_))\n",
    "    \n",
    "    \n",
    "    # ---- PREDICTIONS ----\n",
    "    \n",
    "    results = pd.DataFrame({\"RFC\":RFC_best.predict(X_test),\n",
    "                        \"ExtT\":ExtC_best.predict(X_test),\n",
    "                        \"SVM\":SVMC_best.predict(X_test),\n",
    "                        \"Ada\":ada_best.predict(X_test),\n",
    "                        \"GBC\":GBC_best.predict(X_test)})\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = VotingClassifier(estimators=[('rfc', RFC_best), ('extc', ExtC_best), \n",
    "                                         ('svc', SVMC_best), ('ada',ada_best), ('gbc',GBC_best)], \n",
    "                             voting='soft', n_jobs=n_jobs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 112 candidates, totalling 1120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 712 tasks      | elapsed:    2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost best score: 0.803921568627451\n",
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 1120 out of 1120 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   60.0s\n",
      "[Parallel(n_jobs=4)]: Done 540 out of 540 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees best score: 0.821078431372549\n",
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 540 out of 540 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.8063725490196079\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 144 tasks      | elapsed:    5.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting best score: 0.7990196078431373\n",
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 720 out of 720 | elapsed:   25.2s finished\n",
      "[Parallel(n_jobs=4)]: Done 144 tasks      | elapsed:    5.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine best score: 0.7941176470588235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 280 out of 280 | elapsed:   12.0s finished\n"
     ]
    }
   ],
   "source": [
    "model_cluster_1 = ensamble_modeling(X_trainW, y_trainW, X_testW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 112 candidates, totalling 1120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 608 tasks      | elapsed:    3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost best score: 0.8047091412742382\n",
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 1120 out of 1120 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 540 out of 540 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees best score: 0.8310249307479224\n",
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 540 out of 540 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best score: 0.8337950138504155\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=4)]: Done 720 out of 720 | elapsed:   38.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting best score: 0.8060941828254847\n",
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=4)]: Done 280 out of 280 | elapsed:   40.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine best score: 0.8310249307479224\n"
     ]
    }
   ],
   "source": [
    "model_cluster_2 = ensamble_modeling(X_trainM, y_trainM, X_testM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rfc', RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=10, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=10,\n",
       "            min_wei...      presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=4, voting='soft', weights=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cluster_1.fit(X_trainW, y_trainW)\n",
    "model_cluster_2.fit(X_trainM, y_trainM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cluster_1 = model_cluster_1.predict(X_testW)\n",
    "predictions_cluster_2 = model_cluster_2.predict(X_testM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting predictions according to delivery format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\"PassengerId\":pd.concat([id_trainW,id_trainM,id_testW,id_testM], axis = 0),\n",
    "                            \"Survived\":list(pd.concat([pd.Series(train[train[\"Sex\"] == 1][\"Survived\"].astype(int)),\n",
    "                                                       pd.Series(train[train[\"Sex\"] == 0][\"Survived\"].astype(int)),\n",
    "                                                       pd.Series(predictions_cluster_1),\n",
    "                                                       pd.Series(predictions_cluster_2)],axis=0))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.sort_values(\"PassengerId\")[891:].reset_index().iloc[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv(\"./outputs/complete_2cluster.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
